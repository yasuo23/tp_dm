{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    " data = pd.read_csv(path, delimiter=',')\n",
    " \n",
    " return data\n",
    "data=load(\"DatasetExos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep (ms)     category\n",
      "Acc_x        float64\n",
      "Acc_y        float64\n",
      "Acc_z        float64\n",
      "Gyro_x       float64\n",
      "Gyro_y       float64\n",
      "Gyro_z       float64\n",
      "ID          category\n",
      "Exercise    category\n",
      "Category    category\n",
      "Set          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# data['ep (ms)'] = pd.to_datetime(data['ep (ms)'])\n",
    "data['ep (ms)'] =  data['ep (ms)'] .astype('category')  \n",
    "\n",
    "data['Acc_x'] = pd.to_numeric(data['Acc_x'], errors='coerce') \n",
    "data['Acc_y'] = pd.to_numeric(data['Acc_y'], errors='coerce')  \n",
    "data['Acc_z'] = pd.to_numeric(data['Acc_z'], errors='coerce')  \n",
    "data['Gyro_x'] = pd.to_numeric(data['Gyro_x'], errors='coerce')  \n",
    "data['Gyro_y'] = pd.to_numeric(data['Gyro_y'], errors='coerce')  \n",
    "data['Gyro_z'] = pd.to_numeric(data['Gyro_z'], errors='coerce')  \n",
    "data['ID'] = data['ID'].astype('category')  \n",
    "data['Exercise'] = data['Exercise'].astype('category')  \n",
    "data['Category'] = data['Category'].astype('category')  \n",
    "data['Set'] = data['Set'].where(data['Set'] >= 0,0) \n",
    "data['Set'] = data['Set'].fillna(0)  \n",
    "data['Set']= pd.to_numeric(data['Set'], errors='coerce') \n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "   \n",
    "    \n",
    "    for column in data.select_dtypes(include=[np.number]).columns:\n",
    "        min_val = data[column].min()\n",
    "        max_val = data[column].max()\n",
    "        newmin=0\n",
    "        newmax=1\n",
    "        data[column] =((data[column] - min_val)*(newmax-newmin)/ (max_val - min_val))+newmin\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, threshold=1.5):\n",
    "    \"\"\"\n",
    "    Remove outliers based on the IQR method.\n",
    "    \"\"\"\n",
    "    numerical_data = data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Apply the IQR method to each numerical column\n",
    "    for column in numerical_data.columns:\n",
    "        Q1 = np.percentile(numerical_data[column], 25)\n",
    "        Q3 = np.percentile(numerical_data[column], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define lower and upper bounds\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        # Remove outliers from the numerical column\n",
    "        # data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]=np.nan\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filter out rows where data is outside the bounds\n",
    "data=remove_outliers(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(\n",
    "    lambda x: x.fillna(x.mode()[0]) if x.dtype == 'category' and x.mode().size > 0 else x.fillna(x.mean()) if x.dtype != 'category' else x,\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number missing values ep (ms)     0\n",
      "Acc_x       0\n",
      "Acc_y       0\n",
      "Acc_z       0\n",
      "Gyro_x      0\n",
      "Gyro_y      0\n",
      "Gyro_z      0\n",
      "ID          0\n",
      "Exercise    0\n",
      "Category    0\n",
      "Set         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"number missing values\" ,data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=min_max_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Exercise','ID','ep (ms)','Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[264], line 187\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Example usage (modify according to your specific dataset)\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Assume 'data' is your preprocessed DataFrame\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]:\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# Clustering\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m         clustered_data, centroids \u001b[38;5;241m=\u001b[39m \u001b[43mk_means\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# Evaluate clusters\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         wcss, silhouette_avg \u001b[38;5;241m=\u001b[39m evaluate_clusters(data, clustered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[264], line 115\u001b[0m, in \u001b[0;36mk_means\u001b[1;34m(data, k, max_iters)\u001b[0m\n\u001b[0;32m    112\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cluster_assignments\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Recalculate centroids\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m new_centroids \u001b[38;5;241m=\u001b[39m \u001b[43mdata_scaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_assignments\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_centroid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Check for convergence\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m centroids\u001b[38;5;241m.\u001b[39mequals(new_centroids):\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1829\u001b[0m         ):\n\u001b[0;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1836\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[264], line 116\u001b[0m, in \u001b[0;36mk_means.<locals>.<lambda>\u001b[1;34m(cluster)\u001b[0m\n\u001b[0;32m    112\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cluster_assignments\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Recalculate centroids\u001b[39;00m\n\u001b[0;32m    115\u001b[0m new_centroids \u001b[38;5;241m=\u001b[39m data_scaled\u001b[38;5;241m.\u001b[39mgroupby(cluster_assignments)\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m cluster: \u001b[43mcalculate_centroid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Check for convergence\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m centroids\u001b[38;5;241m.\u001b[39mequals(new_centroids):\n",
      "Cell \u001b[1;32mIn[264], line 67\u001b[0m, in \u001b[0;36mcalculate_centroid\u001b[1;34m(cluster_data)\u001b[0m\n\u001b[0;32m     62\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m cluster_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Create centroid\u001b[39;00m\n\u001b[0;32m     65\u001b[0m centroid \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m     66\u001b[0m     cluster_data[numerical_cols]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mcluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     68\u001b[0m ])\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m centroid\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def distance(x, y, data):\n",
    "    # Convert x and y to pandas Series if they aren't already\n",
    "    x = pd.Series(x)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Get indices of numerical and categorical columns\n",
    "    numerical_indices = [data.columns.get_loc(col) for col in numerical_columns]\n",
    "    categorical_indices = [data.columns.get_loc(col) for col in categorical_columns]\n",
    "    \n",
    "    # Extract numerical values\n",
    "    numerical_X = x.iloc[numerical_indices].values.flatten()\n",
    "    numerical_Y = y.iloc[numerical_indices].values.flatten()\n",
    "    \n",
    "    # Calculate Manhattan distance for numerical columns\n",
    "    manhattan = np.sum(np.abs(numerical_X - numerical_Y))\n",
    "    \n",
    "    # # Extract categorical values\n",
    "    # categorical_X = x.iloc[categorical_indices].values.flatten()\n",
    "    # categorical_Y = y.iloc[categorical_indices].values.flatten()\n",
    "    \n",
    "    # # Calculate Hamming distance for categorical columns\n",
    "    # mismatches = np.sum(categorical_X != categorical_Y)\n",
    "    # if (categorical_X==0):\n",
    "    #     categorical_X=1\n",
    "    # hamming = mismatches / len(categorical_X)\n",
    "    \n",
    "    # Weighted combination of distances\n",
    "    return manhattan \n",
    "\n",
    "def initialize_centroids(data, k):\n",
    "    \"\"\"\n",
    "    Initialize centroids by randomly selecting k unique instances from the data.\n",
    "    \n",
    "    :param data: DataFrame\n",
    "    :param k: int (number of clusters)\n",
    "    :return: DataFrame of centroids\n",
    "    \"\"\"\n",
    "    return data.sample(n=k, replace=False).reset_index(drop=True)\n",
    "\n",
    "def calculate_centroid(cluster_data):\n",
    "    \"\"\"\n",
    "    Calculate the centroid of a cluster.\n",
    "    \n",
    "    :param cluster_data: DataFrame of cluster points\n",
    "    :return: Centroid (Series)\n",
    "    \"\"\"\n",
    "    # For numerical columns, take mean\n",
    "    numerical_cols = cluster_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # For categorical columns, take mode\n",
    "    categorical_cols = cluster_data.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Create centroid\n",
    "    centroid = pd.concat([\n",
    "        cluster_data[numerical_cols].mean(),\n",
    "        cluster_data[categorical_cols].mode().iloc[0]\n",
    "    ])\n",
    "    \n",
    "    return centroid\n",
    "\n",
    "def closest_cluster(instance, centroids, data):\n",
    "    \"\"\"\n",
    "    Find the closest cluster for a given instance.\n",
    "    \n",
    "    :param instance: Single data point\n",
    "    :param centroids: Centroids of clusters\n",
    "    :param data: Original dataset\n",
    "    :return: Index of the closest cluster\n",
    "    \"\"\"\n",
    "    distances = [distance(c, instance, data) for c in centroids.values]\n",
    "    return np.argmin(distances)\n",
    "\n",
    "def k_means(data, k, max_iters=100):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering.\n",
    "    \n",
    "    :param data: DataFrame to cluster\n",
    "    :param k: Number of clusters\n",
    "    :param max_iters: Maximum number of iterations\n",
    "    :return: Clustered data and final centroids\n",
    "    \"\"\"\n",
    "    # Preprocess data\n",
    "    # Separate features and categorical columns\n",
    "    numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Standardize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = data.copy()\n",
    "    data_scaled[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "    \n",
    "    # Initialize centroids\n",
    "    centroids = initialize_centroids(data_scaled, k)\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # Assign clusters\n",
    "        cluster_assignments = data_scaled.apply(\n",
    "            lambda row: closest_cluster(row, centroids, data_scaled), \n",
    "            axis=1\n",
    "        )\n",
    "        data['cluster'] = cluster_assignments\n",
    "        \n",
    "        # Recalculate centroids\n",
    "        new_centroids = cluster.mean(axis=0)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if centroids.equals(new_centroids):\n",
    "            print('Convergence reached.')\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return data, centroids\n",
    "\n",
    "def evaluate_clusters(data, cluster_assignments):\n",
    "    \"\"\"\n",
    "    Evaluate clustering performance.\n",
    "    \n",
    "    :param data: Original dataset\n",
    "    :param cluster_assignments: Cluster labels\n",
    "    :return: WCSS and Silhouette score\n",
    "    \"\"\"\n",
    "    # Prepare data for evaluation (use original numerical columns)\n",
    "    numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    data_for_eval = data[numerical_cols]\n",
    "    \n",
    "    # Calculate Within-Cluster Sum of Squares (WCSS)\n",
    "    wcss = np.sum([\n",
    "        np.sum((data_for_eval[cluster_assignments == c] - \n",
    "                data_for_eval[cluster_assignments == c].mean())**2)\n",
    "        for c in np.unique(cluster_assignments)\n",
    "    ])\n",
    "    \n",
    "    # Calculate Silhouette Score\n",
    "    silhouette_avg = silhouette_score(data_for_eval, cluster_assignments)\n",
    "    \n",
    "    return wcss, silhouette_avg\n",
    "\n",
    "def visualize_with_pca(data, cluster_assignments, title):\n",
    "    \"\"\"\n",
    "    Visualize clusters using PCA.\n",
    "    \n",
    "    :param data: Original dataset\n",
    "    :param cluster_assignments: Cluster labels\n",
    "    :param title: Plot title\n",
    "    \"\"\"\n",
    "    # Prepare data for PCA (use only numerical columns)\n",
    "    numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    data_for_pca = data[numerical_cols]\n",
    "    \n",
    "    # Reduce data to 2D using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    data_2d = pca.fit_transform(data_for_pca)\n",
    "    \n",
    "    # Visualize clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(data_2d[:, 0], data_2d[:, 1], \n",
    "                          c=cluster_assignments, \n",
    "                          cmap='viridis', \n",
    "                          s=30, \n",
    "                          alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PC1 (1st principal component)')\n",
    "    plt.ylabel('PC2 (2nd principal component)')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (modify according to your specific dataset)\n",
    "\n",
    "    # Assume 'data' is your preprocessed DataFrame\n",
    "for k in [2, 3, 4, 5]:\n",
    "        # Clustering\n",
    "        clustered_data, centroids = k_means(data, k)\n",
    "        \n",
    "        # Evaluate clusters\n",
    "        wcss, silhouette_avg = evaluate_clusters(data, clustered_data['cluster'])\n",
    "        \n",
    "        # Visualize with PCA\n",
    "        visualize_with_pca(data, clustered_data['cluster'], f\"K-Means with k={k}\")\n",
    "        \n",
    "        # Print evaluation results\n",
    "        print(f\"Results for k={k}:\")\n",
    "        print(f\"- Intra-cluster inertia (WCSS): {wcss:.2f}\")\n",
    "        print(f\"- Silhouette score: {silhouette_avg:.2f}\")\n",
    "\n",
    "# Uncomment and run when you have your dataset ready\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance(x, y, data):\n",
    "    numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "    # Get indices of numerical columns\n",
    "    numerical_indices = [data.columns.get_loc(col) for col in numerical_columns]\n",
    "\n",
    "    categorical_indices = [data.columns.get_loc(col) for col in categorical_columns]\n",
    "    x = pd.Series(x)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    # Extract numerical and categorical values for x and y\n",
    "    numerical_X = x.iloc[numerical_indices].values\n",
    "    numerical_Y = y.iloc[numerical_indices].values\n",
    "    numerical_X  = [item[0] for item in  numerical_X ]\n",
    "    # Calculate Manhattan distance for numerical columns\n",
    "    manhattan = sum(abs(numerical_X - numerical_Y))\n",
    "    \n",
    "    categorical_X = x.iloc[categorical_indices].values\n",
    "    categorical_Y = y.iloc[categorical_indices].values\n",
    "    categorical_X  = [item[0] for item in  categorical_X ]\n",
    "    \n",
    "    # Calculate Hamming distance for categorical columns\n",
    "    mismatches = sum(a != b for a, b in zip(categorical_X, categorical_Y))\n",
    "    hamming = mismatches / len(categorical_X)\n",
    "    \n",
    "    # return ((len(numerical_columns) / len(data.columns)) * manhattan) + ((len(categorical_columns) / len(data.columns)) * hamming)\n",
    "    return ( manhattan) + (  hamming)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sortedval(data, x ,pred):\n",
    "#     d=[]\n",
    "    \n",
    "#     # Drop the prediction column once to avoid redundant computation\n",
    "#     data_dropped = data.drop(columns=[pred])\n",
    "    \n",
    "#     # Iterate through each instance in the dataset\n",
    "#     for _, row in data.iterrows():\n",
    "#         dist = distance(x, row.drop(pred), data_dropped)\n",
    "#         d.append((dist, row[pred]))\n",
    "    \n",
    "#     # Sort the list by the calculated distance\n",
    "#     d.sort(key=lambda item: item[0])\n",
    "    \n",
    "#     return d\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def maxclass(d,k):\n",
    "#   _, l = zip(*d[:k])\n",
    "#   class_counts = Counter(l)\n",
    "    \n",
    "#   dominant, frequency = class_counts.most_common(1)[0]\n",
    "#   return dominant\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def knn(k,data,pred,x):\n",
    "#    d= sortedval(data, x ,pred)\n",
    "#    return maxclass(d,k)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance =['2024-11-20 18:09:51.000', -0.137, 1.066, 0.8215, -6.597, 0.808, 1.985, 'B', 'medium', 30]\n",
    "# typed_instance = [(i, type(i)) for i in instance]\n",
    "# print ('pour k=3')\n",
    "# print(knn(3,data,'Exercise',typed_instance))\n",
    "# print ('pour k=10')\n",
    "# print(knn(10,data,'Exercise',typed_instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Exercise','ID','ep (ms)','Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids(data, k):\n",
    "    \"\"\"\n",
    "    Initialize centroids by randomly selecting k unique instances from the data.\n",
    "    :param data: numpy array of shape (n_instances, n_features)\n",
    "    :param k: int (number of clusters)\n",
    "    :return: numpy array of shape (k, n_features)\n",
    "    \"\"\"\n",
    "    centroids = []  # List to store the centroids\n",
    "    for _ in range(k):  # Loop k times to select k centroids\n",
    "     centroids.append(data.sample(replace=False).iloc[0])  # Randomly select a single instance and add it to centroids\n",
    "    return pd.DataFrame(centroids).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_cluster(instance, centroids,data):\n",
    "    distances=[]\n",
    "    for c in centroids:\n",
    "     d = distance(c, instance, data)\n",
    "     distances.append((d))\n",
    "    \n",
    "#     # Sort the list by the calculated distance\n",
    "#     d.sort(key=lambda item: item[0])\n",
    "\n",
    "    return np.argmin(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centroid(cluster):\n",
    "    return cluster.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, k, max_iters=100):\n",
    "    \"\"\"\n",
    "    K-means algorithm that stops when all clusters contain the same number of instances.\n",
    "    :param data: numpy array of shape (n_instances, n_features)\n",
    "    :param k: int (number of clusters)\n",
    "    :param max_iters: int (maximum number of iterations)\n",
    "    :return: (numpy array of cluster assignments, numpy array of centroids)\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize centroids randomly from the data\n",
    "    centroids = initialize_centroids(data, k)\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Step 2: Assign each instance to the nearest centroid\n",
    "        cluster_assignments = np.array([closest_cluster(instance, centroids,data) for instance in data])\n",
    "\n",
    "        # Step 3: Count the number of instances in each cluster\n",
    "        _, counts = np.unique(cluster_assignments, return_counts=True)\n",
    "\n",
    "        # Step 4: Check if all clusters have the same number of instances\n",
    "        if len(set(counts)) == 1:  # If all counts are equal\n",
    "            break\n",
    "\n",
    "        # Step 5: Update centroids\n",
    "        centroids = np.array([calculate_centroid(data[cluster_assignments == c]) for c in range(k)])\n",
    "\n",
    "    return cluster_assignments, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "# # def evaluate_clusters(data, cluster_assignments):\n",
    "# #     wcss = np.sum([np.linalg.norm(data[cluster_assignments == c] - np.mean(data[cluster_assignments == c], axis=0))**2 \n",
    "# #                    for c in np.unique(cluster_assignments)])\n",
    "# #     silhouette_avg = silhouette_score(data, cluster_assignments)\n",
    "# #     return wcss, silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[270], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Tester avec PCA pour visualisation\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]:\n\u001b[1;32m---> 21\u001b[0m     cluster_assignments, centroids \u001b[38;5;241m=\u001b[39m \u001b[43mk_means\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     wcss, silhouette_avg \u001b[38;5;241m=\u001b[39m evaluate_clusters(data, cluster_assignments)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Visualisation avec PCA\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[268], line 14\u001b[0m, in \u001b[0;36mk_means\u001b[1;34m(data, k, max_iters)\u001b[0m\n\u001b[0;32m     10\u001b[0m centroids \u001b[38;5;241m=\u001b[39m initialize_centroids(data, k)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Step 2: Assign each instance to the nearest centroid\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     cluster_assignments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([closest_cluster(instance, centroids,data) \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Step 3: Count the number of instances in each cluster\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     _, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(cluster_assignments, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[268], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m centroids \u001b[38;5;241m=\u001b[39m initialize_centroids(data, k)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Step 2: Assign each instance to the nearest centroid\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     cluster_assignments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mclosest_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Step 3: Count the number of instances in each cluster\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     _, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(cluster_assignments, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[266], line 4\u001b[0m, in \u001b[0;36mclosest_cluster\u001b[1;34m(instance, centroids, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m     distances\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m centroids:\n\u001b[1;32m----> 4\u001b[0m      d \u001b[38;5;241m=\u001b[39m \u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m      distances\u001b[38;5;241m.\u001b[39mappend((d))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     # Sort the list by the calculated distance\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     d.sort(key=lambda item: item[0])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[264], line 22\u001b[0m, in \u001b[0;36mdistance\u001b[1;34m(x, y, data)\u001b[0m\n\u001b[0;32m     19\u001b[0m categorical_indices \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Extract numerical values\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m numerical_X \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     23\u001b[0m numerical_Y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[numerical_indices]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate Manhattan distance for numerical columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fonction pour visualiser avec PCA\n",
    "def visualize_with_pca(data, cluster_assignments, centroids, title):\n",
    "    # Réduire les données en 2 dimensions avec PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    data_2d = pca.fit_transform(data)\n",
    "    centroids_2d = pca.transform(centroids)\n",
    "    \n",
    "    # Visualisation des clusters\n",
    "    plt.scatter(data_2d[:, 0], data_2d[:, 1], c=cluster_assignments, cmap='viridis', s=30, alpha=0.6)\n",
    "    plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], color='red', marker='x', s=200, label='Centroids')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PC1 (1ère composante principale)')\n",
    "    plt.ylabel('PC2 (2ème composante principale)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Tester avec PCA pour visualisation\n",
    "for k in [2, 5, 6]:\n",
    "    cluster_assignments, centroids = k_means(data, k)\n",
    "    wcss, silhouette_avg = evaluate_clusters(data, cluster_assignments)\n",
    "    \n",
    "    # Visualisation avec PCA\n",
    "    visualize_with_pca(data, cluster_assignments, centroids, f\"K-Means avec k={k} (Visualisation PCA)\")\n",
    "    \n",
    "    # Afficher les résultats d'évaluation\n",
    "    print(f\"Résultats pour k={k}:\")\n",
    "    print(f\"- Inertie intra-cluster (WCSS) : {wcss:.2f}\")\n",
    "    print(f\"- Score de silhouette : {silhouette_avg:.2f}\")\n",
    "# #     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9009, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "9004    0\n",
      "9005    0\n",
      "9006    0\n",
      "9007    1\n",
      "9008    0\n",
      "Name: cluster, Length: 9009, dtype: int32\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[241], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Test with PCA visualization for different k values\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]:\n\u001b[1;32m---> 48\u001b[0m     data, centroids \u001b[38;5;241m=\u001b[39m \u001b[43mk_means\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     wcss, silhouette_avg \u001b[38;5;241m=\u001b[39m evaluate_clusters(data, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Visualize with PCA\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[241], line 9\u001b[0m, in \u001b[0;36mk_means\u001b[1;34m(data, k, max_iters)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Step 2: Assign clusters\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosest_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Step 3: Recalculate centroids\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     new_centroids \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m cluster: calculate_centroid(cluster\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[241], line 9\u001b[0m, in \u001b[0;36mk_means.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Step 2: Assign clusters\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mclosest_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Step 3: Recalculate centroids\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     new_centroids \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m cluster: calculate_centroid(cluster\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[235], line 4\u001b[0m, in \u001b[0;36mclosest_cluster\u001b[1;34m(instance, centroids, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m     distances\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m centroids:\n\u001b[1;32m----> 4\u001b[0m      d \u001b[38;5;241m=\u001b[39m \u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m      distances\u001b[38;5;241m.\u001b[39mappend((d))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     # Sort the list by the calculated distance\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     d.sort(key=lambda item: item[0])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[228], line 14\u001b[0m, in \u001b[0;36mdistance\u001b[1;34m(x, y, data)\u001b[0m\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract numerical and categorical values for x and y\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m numerical_X \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m numerical_Y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[numerical_indices]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     16\u001b[0m numerical_X  \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m  numerical_X ]\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32mc:\\Users\\belou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "def k_means(data, k, max_iters=100):\n",
    "    # Step 1: Initialize centroids randomly from the data\n",
    "    centroids = initialize_centroids(data, k)\n",
    "    data['cluster'] = np.random.randint(0, k, size=len(data))\n",
    "    print(data['cluster'])\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Step 2: Assign clusters\n",
    "        data['cluster'] = data.apply(lambda row: closest_cluster(row[:-1], centroids, data), axis=1)\n",
    "\n",
    "        # Step 3: Recalculate centroids\n",
    "        new_centroids = data.groupby('cluster').apply(lambda cluster: calculate_centroid(cluster.iloc[:, :-1])).reset_index(drop=True)\n",
    "\n",
    "        # Step 4: Check for convergence\n",
    "        if centroids.equals(new_centroids):\n",
    "            print('Convergence reached.')\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return data, centroids\n",
    "\n",
    "# Evaluate clusters using WCSS and silhouette score\n",
    "def evaluate_clusters(data, cluster_assignments):\n",
    "    wcss = np.sum([np.linalg.norm(data[cluster_assignments == c] - np.mean(data[cluster_assignments == c], axis=0))**2\n",
    "                   for c in np.unique(cluster_assignments)])\n",
    "    silhouette_avg = silhouette_score(data, cluster_assignments)\n",
    "    return wcss, silhouette_avg\n",
    "\n",
    "# Visualize clusters with PCA\n",
    "def visualize_with_pca(data, cluster_assignments, centroids, title):\n",
    "    # Reduce data to 2D using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    data_2d = pca.fit_transform(data)\n",
    "    centroids_2d = pca.transform(centroids)\n",
    "\n",
    "    # Visualize clusters\n",
    "    plt.scatter(data_2d[:, 0], data_2d[:, 1], c=cluster_assignments, cmap='viridis', s=30, alpha=0.6)\n",
    "    plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], color='red', marker='x', s=200, label='Centroids')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PC1 (1st principal component)')\n",
    "    plt.ylabel('PC2 (2nd principal component)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Test with PCA visualization for different k values\n",
    "for k in [2, 5, 6]:\n",
    "    data, centroids = k_means(data, k)\n",
    "    wcss, silhouette_avg = evaluate_clusters(data, data['cluster'])\n",
    "    \n",
    "    # Visualize with PCA\n",
    "    visualize_with_pca(data.iloc[:, :-1], data['cluster'], centroids, f\"K-Means with k={k} (PCA Visualization)\")\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(f\"Results for k={k}:\")\n",
    "    print(f\"- Intra-cluster inertia (WCSS): {wcss:.2f}\")\n",
    "    print(f\"- Silhouette score: {silhouette_avg:.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
